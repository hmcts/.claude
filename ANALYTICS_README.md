# Analytics Scripts Guide

This directory contains scripts to analyze Claude Code usage, link it to development metrics, and calculate ROI.

---

## Quick Reference: What Metric Do You Need?

| I Want To Know... | Run This Script | Needs CSVs? | API Only? |
|-------------------|-----------------|-------------|-----------|
| **Combine multiple developer CSVs** | `merge_analytics.js` | ‚úÖ Yes | ‚ùå |
| **How many tokens per story point?** | `tokens_per_story_point.js` | ‚úÖ Yes | ‚ùå |
| **Current sprint velocity and progress** | `jira_story_points.js` | ‚ùå No | ‚úÖ Yes |
| **PR metrics across multiple repos** | `multi_repo_pr_metrics.js` | ‚ùå No | ‚úÖ Yes |
| **Detailed PR analysis with JIRA links** | `comprehensive_analytics.js` | ‚úÖ Yes | ‚ùå |
| **PR metrics for a single repo** | `comprehensive_pr_metrics.js` | ‚ùå No | ‚úÖ Yes |
| **When sessions hit context limits** | `analyze_time_to_context_window.js` | ‚úÖ Yes | ‚ùå |

**Legend:**
- ‚úÖ **Needs CSVs** = Requires analytics data from `.claude/analytics/` directory (generated by analytics.sh hook)
- ‚úÖ **API Only** = Can run standalone with just API tokens, no CSV files needed

---

## Setup (Required for All Scripts)

### 1. Install Dependencies
```bash
# No external dependencies - uses Node.js built-in modules only
node --version  # Requires Node.js 14+
```

### 2. Set Environment Variables

**For GitHub scripts:**
```bash
export GITHUB_TOKEN="ghp_your_token_here"
# Get token at: https://github.com/settings/tokens/new?scopes=repo
```

**For JIRA scripts:**
```bash
export JIRA_PERSONAL_TOKEN="your_jira_token_here"
# Get token at: https://tools.hmcts.net/jira/secure/ViewProfile.jspa?selectedTab=com.atlassian.pats.pats-plugin:jira-user-personal-access-tokens
```

**For SonarQube scripts:**
```bash
export SONARQUBE_TOKEN="your_sonar_token_here"
# Get token at: https://sonarcloud.io/account/security
```

---

## Script Details

### 1. tokens_per_story_point.js

**Purpose:** Calculate how many Claude Code tokens are used per JIRA story point

**Data Source:** ‚úÖ Requires CSVs + APIs

**What It Does:**
- Reads `costs.csv` and `sessions.csv` from `.claude/analytics/`
- Links sessions ‚Üí commits ‚Üí PRs ‚Üí JIRA tickets
- Fetches story points from JIRA
- Calculates tokens per story point

**Requires:**
- ‚úÖ `.claude/analytics/costs.csv` file (token data)
- ‚úÖ `.claude/analytics/sessions.csv` file (commit SHAs)
- üîë `GITHUB_TOKEN` environment variable
- üîë `JIRA_PERSONAL_TOKEN` environment variable

**Usage:**
```bash
# Analyze default repo for last 30 days
node tokens_per_story_point.js

# Analyze specific repo for last 60 days
node tokens_per_story_point.js --repo hmcts/pip-frontend --days 60

# Analyze VIBE project for last 14 days
node tokens_per_story_point.js --repo hmcts/vibe-service --days 14
```

**Example Output:**
```
VIBE-123: Implement user login
  Story Points: 3
  Total Tokens: 45,000
  Tokens/Point: 15,000
  PRs: #234

SUMMARY:
Total Tickets Analyzed: 12
Total Story Points: 34
Total Tokens Used: 850,000
Average Tokens Per Story Point: 25,000

Breakdown by Story Point Size:
  1 points: 3 tickets, avg 8,000 tokens (8,000 tokens/point)
  2 points: 4 tickets, avg 18,000 tokens (9,000 tokens/point)
  3 points: 3 tickets, avg 45,000 tokens (15,000 tokens/point)
  5 points: 2 tickets, avg 120,000 tokens (24,000 tokens/point)
```

**Use Cases:**
- Estimate token budget for upcoming sprint
- Understand which ticket sizes are most efficient
- Justify Claude Code costs to management

---

### 2. jira_story_points.js

**Purpose:** Get current sprint velocity and story point progress from JIRA

**What It Does:**
- Fetches active sprint data from JIRA board
- Calculates completed vs in-progress story points
- Shows sprint timeline and velocity
- Can also query by date range

**Requires:**
- `JIRA_PERSONAL_TOKEN` environment variable

**Usage:**
```bash
# Get current active sprint
node jira_story_points.js sprint

# Get story points completed in a date range
node jira_story_points.js date-range 2025-10-22 2025-10-29
```

**Example Output:**
```
=== Current Sprint: Cath Sprint 3 ===
Sprint Timeline:
  Start: 28th Oct 2025
  End: 10th Nov 2025
  Duration: 13 days
  Days Elapsed: 9 (69.2%)

Story Points:
  Total Committed: 55 points
  Completed: 0 points (0%)
  In Progress: 55 points (100%)

Status: Behind Schedule
```

**Use Cases:**
- Track sprint progress
- Report velocity to stakeholders
- Identify if sprint is on track

---

### 3. comprehensive_analytics.js

**Purpose:** Comprehensive analysis linking Claude Code costs to GitHub PRs and JIRA tickets

**What It Does:**
- Reads all analytics CSVs (`costs.csv`, `sessions.csv`, `turns.csv`)
- Links sessions to GitHub PRs via commit SHAs
- Extracts JIRA ticket IDs from PR titles
- Calculates total costs, tokens, and time per PR
- Shows developer productivity metrics

**Requires:**
- `GITHUB_TOKEN` environment variable
- `.claude/analytics/` directory with CSV files

**Usage:**
```bash
node comprehensive_analytics.js
```

**Example Output:**
```
=== Pull Request Analysis ===
Total PRs Analyzed: 24

PR #234: VIBE-123: Implement user login
  JIRA Ticket: VIBE-123
  Total Cost: $4.50
  Total Tokens: 45,000 (32,000 input, 13,000 output)
  Sessions: 3
  Time: 4.2 hours
  Status: Merged
  Files Changed: 12
```

**Use Cases:**
- Detailed cost breakdown per PR
- Link development work to JIRA tickets
- Understand which PRs were most expensive
- Calculate ROI per feature

---

### 4. comprehensive_pr_metrics.js

**Purpose:** Analyze pull requests for a single repository with quality metrics

**What It Does:**
- Fetches PRs from GitHub for specified repo and date range
- Analyzes PR checks (tests, linting, SonarQube)
- Calculates merge time, review time, and comments
- Filters out dependency updates (Dependabot, Renovate)

**Requires:**
- `GITHUB_TOKEN` environment variable

**Usage:**
```bash
# Analyze last 90 days (default)
node comprehensive_pr_metrics.js

# Analyze specific time range
node comprehensive_pr_metrics.js --start 2025-10-01 --end 2025-10-31
```

**Example Output:**
```
=== PR Quality Metrics ===
Repository: hmcts/pip-frontend
Time Range: Oct 1 - Oct 31, 2025

Total PRs: 45 (excluding 12 dependency updates)

Average Metrics:
  Time to Merge: 2.3 days
  Review Comments: 3.2 per PR
  Files Changed: 8.5 per PR

PR Checks:
  Tests Passed: 98%
  Linting Passed: 95%
  SonarQube Passed: 87%
```

**Use Cases:**
- Track PR quality over time
- Identify bottlenecks in review process
- Report on code quality metrics

---

### 5. multi_repo_pr_metrics.js

**Purpose:** Analyze PRs across multiple repositories with SonarQube integration

**What It Does:**
- Fetches PRs from multiple configured repositories
- Gets SonarQube metrics for each PR (bugs, code smells, coverage)
- Aggregates metrics across all repos
- Shows which repos have the best/worst quality

**Requires:**
- `GITHUB_TOKEN` environment variable
- `SONARQUBE_TOKEN` environment variable

**Usage:**
```bash
node multi_repo_pr_metrics.js
```

**Configuration:**
Edit the `CONFIG` section in the script to add/remove repos:
```javascript
const CONFIG = {
  REPOS: [
    'hmcts/pip-frontend',
    'hmcts/pip-data-management',
    'hmcts/pip-account-management',
  ],
  // ...
};
```

**Example Output:**
```
=== Multi-Repo PR Metrics ===

Repository: hmcts/pip-frontend
  Total PRs: 34 (last 90 days)
  Avg Comments: 2.8 per PR
  SonarQube Metrics:
    Bugs: 0.2 per PR
    Code Smells: 3.5 per PR
    Test Coverage: 78%

Repository: hmcts/pip-data-management
  Total PRs: 28
  Avg Comments: 3.1 per PR
  SonarQube Metrics:
    Bugs: 0.1 per PR
    Code Smells: 2.1 per PR
    Test Coverage: 82%

SUMMARY:
  Total PRs Across All Repos: 62
  Average Code Quality Score: 8.2/10
```

**Use Cases:**
- Compare quality across multiple repos
- Identify which repos need attention
- Report on organization-wide metrics

---

### 6. analyze_time_to_context_window.js

**Purpose:** Analyze when Claude Code sessions hit context window limits

**What It Does:**
- Reads `costs.csv` to get token usage per turn
- Identifies sessions approaching context limits
- Shows which sessions needed compacting
- Helps understand context usage patterns

**Requires:**
- `.claude/analytics/costs.csv` file

**Usage:**
```bash
node analyze_time_to_context_window.js
```

**Example Output:**
```
=== Context Window Analysis ===

Session: 255f1ac0-4420-4069-917a-bcd084f4793e
  Total Turns: 45
  Max Tokens in Turn: 182,000
  Compacted at Turn: 38 (180,000 tokens)
  Context Efficiency: 85%

High Token Turns:
  Turn 12: 95,000 tokens (reading large file)
  Turn 25: 120,000 tokens (multi-file edit)
  Turn 38: 182,000 tokens (comprehensive search)

SUMMARY:
  Sessions Analyzed: 156
  Sessions Requiring Compact: 23 (14.7%)
  Average Tokens at Compact: 175,000
```

**Use Cases:**
- Optimize prompt strategies to avoid compacting
- Understand which operations use most context
- Identify sessions that need better planning

---

## Common Workflows

### Calculate Sprint ROI

```bash
# 1. Get current sprint story points
node jira_story_points.js sprint

# 2. Calculate tokens used per story point
node tokens_per_story_point.js --days 14

# 3. Get detailed cost breakdown
node comprehensive_analytics.js
```

**Result:** You can say "We completed 34 story points using 850,000 tokens ($25.50), averaging $0.75 per story point"

---

### Monthly Quality Report

```bash
# 1. Multi-repo PR metrics
node multi_repo_pr_metrics.js

# 2. Single repo detailed analysis
node comprehensive_pr_metrics.js

# 3. Link to JIRA tickets
node comprehensive_analytics.js
```

**Result:** Comprehensive quality metrics across all repos with cost attribution

---

### Budget Planning for Next Sprint

```bash
# 1. Historical tokens per story point
node tokens_per_story_point.js --days 90

# 2. Current sprint velocity
node jira_story_points.js sprint
```

**Calculation:**
```
Planned Story Points: 40
Historical Avg: 25,000 tokens/point
Estimated Tokens: 40 √ó 25,000 = 1,000,000 tokens
Estimated Cost: ~$30 (at Bedrock pricing)
```

---

## Data Files

All scripts read from `.claude/analytics/`:

| File | Content | Updated By |
|------|---------|-----------|
| `costs.csv` | Token usage per turn | analytics.sh hook |
| `sessions.csv` | Session metadata with commit SHAs | analytics.sh hook |
| `turns.csv` | Turn-level details | analytics.sh hook |
| `.git-cache.json` | Cached git info for performance | analytics.sh hook |

---

## Troubleshooting

### "Error: GITHUB_TOKEN not set"
```bash
export GITHUB_TOKEN="ghp_your_token_here"
# Get at: https://github.com/settings/tokens/new?scopes=repo
```

### "Error: costs.csv not found"
Make sure you're running the script from a directory with `.claude/analytics/` containing the CSV files. The analytics hook must have run at least once to generate these files.

### "GitHub API returned 403"
Your token may have expired or lacks required permissions. Generate a new token with `repo` scope.

### "JIRA API returned 401"
Your JIRA personal access token may have expired. Generate a new one from your JIRA profile.

### Script runs but shows 0 results
- Check the `--days` parameter - you may need to look further back
- Verify the `--repo` parameter matches your repository name
- Ensure PR titles contain JIRA ticket IDs (e.g., "VIBE-123: ...")

---

## Adding New Metrics

Want to track something new? Here's the data you can access:

**From costs.csv:**
- `session_id`, `user_id`, `turn_number`, `message_id`
- `input_tokens`, `output_tokens`, `total_tokens`
- `input_cost_usd`, `output_cost_usd`, `total_cost_usd`
- `timestamp`, `model`

**From sessions.csv:**
- `session_id`, `user_id`, `repo_url`, `repo_name`, `branch`
- `head_commit` ‚Üê Key for linking to Git/PRs
- `started_at`, `ended_at`, `turn_count`
- `total_cost_usd`, `interrupted_turns`

**From GitHub API:**
- PR title, body, number, state
- created_at, merged_at, closed_at
- commits, files changed, additions, deletions
- comments, reviews, checks

**From JIRA API:**
- Story points (`customfield_10004`)
- Status, assignee, labels
- Issue type, priority, resolution
- Status change history (changelog)

---

## Contributing

When creating new scripts:
1. Follow the existing pattern (Node.js, no external dependencies)
2. Add error handling for API calls
3. Support command-line arguments where appropriate
4. Update this README with script details
5. Add example output

---

## Support

For issues or questions:
- Check the troubleshooting section above
- Review the hook analytics.sh:2.0.0-bedrock-caching for data generation
- File an issue in the .claude repository
